{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libc10_cuda.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40097/3574709115.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmsynth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientnet_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodeleff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/msynthconda/lib/python3.7/site-packages/torchaudio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchaudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from torchaudio import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mcompliance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfunctional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/msynthconda/lib/python3.7/site-packages/torchaudio/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/msynthconda/lib/python3.7/site-packages/torchaudio/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# which depends on `libtorchaudio` and dynamic loader will handle it for us.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/msynthconda/lib/python3.7/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/msynthconda/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: libc10_cuda.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image \n",
    "import torch\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "import msynth.efficientnet_pytorch.model as modeleff\n",
    "from torch.autograd import Variable\n",
    "import torchaudio \n",
    "import einops \n",
    "import os\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(controls, samples): #(16,1,4)\n",
    "    sampled = torch.bmm(controls,\n",
    "            samples)    \n",
    "    synthesized_audio = einops.rearrange(sampled, 'b d s -> d (b s)')#(1,465696)\n",
    "    return synthesized_audio\n",
    "\n",
    "def get_melspec(audio):\n",
    "    stft = torch.stft(audio,n_fft=441*4,hop_length=441*2)\n",
    "    real_part, imag_part = stft.unbind(-1)\n",
    "    magnitude_concat = torch.sqrt(real_part ** 2 + imag_part ** 2)\n",
    "    mel_output = torch.matmul(mel_basis, magnitude_concat.float())\n",
    "    log_mel_spec_concat = torch.log10(torch.clamp(mel_output, min=1e-5))#(1,128,529)\n",
    "    return log_mel_spec_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionWithNumericalGrad(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(cxt, synth_params):\n",
    "        ctx.save_for_backward(synth_params)\n",
    "        # do forward process\n",
    "        synth_signal = sampler(synth_params)\n",
    "\n",
    "        return synth_signal\n",
    "\n",
    "    def synth_func(synth_params):\n",
    "\n",
    "        return synthesized_audio\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(cxt, grad_output):\n",
    "\n",
    "        epsilon = 0.1 \n",
    "\n",
    "        synth_params = cxt.saved_tensors\n",
    "  \n",
    "        grads_synth_params = torch.empty_like(synth_params)\n",
    "\n",
    "        # generate random vector of +-1s\n",
    "        delta_k= np.random.randint(0,high=1,size=synth_params.shape)\n",
    "        delta_k[delta_k==0]=-1\n",
    "        print(delta_k)\n",
    "        #delta_k = rademacher(synth_params.shape).numpy()\n",
    "\n",
    "        params = []\n",
    "        \n",
    "        # synth +- forward and backward passes\n",
    "        J_plus = sampler(synth_params + delta_k)\n",
    "\n",
    "        J_minus = sampler(synth_params - delta_k)\n",
    "\n",
    "        grad_synth = J_plus - J_minus\n",
    "\n",
    "        # loop for each element of synth_params\n",
    "        params_sublist = []\n",
    "        for sub_p_idx in range(len(synth_params)):\n",
    "            grad_s = grad_synth / (2 * epsilon * delta_k[sub_p_idx])\n",
    "            params.append(np.sum(grad_output * grad_s))\n",
    "\n",
    "        grad_synth = np.array(synth_params)\n",
    "\n",
    "        return grad_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = modeleff.EfficientNet.from_name('efficientnet-b0')\n",
    "model._change_in_channels(1)\n",
    "    \n",
    "list_of_notes = [\"47.wav\",\"44.wav\",\"42.wav\",\"40.wav\"]\n",
    "song=[\"mary.wav\"]\n",
    "\n",
    "ground_truth = torch.tensor([[0,1,0,0],[0,0,1,0],[0,0,0,1],[0,0,1,0],\n",
    "        [0,1,0,0],[0,1,0,0],[0,1,0,0],[0,1,0,0],\n",
    "        [0,0,1,0],[0,0,1,0],[0,0,1,0],[0,0,1,0],[1,0,0,0],\n",
    "        [1,0,0,0],[1,0,0,0],[1,0,0,0]]).type(torch.DoubleTensor)\n",
    "        \n",
    "audio_d,sr = torchaudio.load(\"../data/musicfiles/\" + list_of_notes[0])\n",
    "audio_b,sr = torchaudio.load(\"../data/musicfiles/\" + list_of_notes[1])\n",
    "audio_a,sr = torchaudio.load(\"../data/musicfiles/\" + list_of_notes[2])\n",
    "audio_g,sr = torchaudio.load(\"../data/musicfiles/\" + list_of_notes[3])\n",
    "mary,sr = torchaudio.load(\"../data/musicfiles/\" + song[0])\n",
    "\n",
    "samples = torch.cat([torch.unsqueeze(audio_d,dim=0),torch.unsqueeze(audio_b,dim=0),\n",
    "torch.unsqueeze(audio_a,dim=0),torch.unsqueeze(audio_g,dim=0)],dim=0) #(4,1,29106)\n",
    "samples = samples.permute((1,0,2)).repeat(16,1,1).type(torch.DoubleTensor) #(16,4,29106)\n",
    "resynthesized_mary = sampler(torch.unsqueeze(ground_truth,dim=1),samples)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "ground_truth = torch.unsqueeze(ground_truth, dim=2) #(16,4,1)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "mel_basis = librosa.filters.mel(44100,n_fft=441*4,n_mels=128)\n",
    "mel_basis = torch.from_numpy(mel_basis).float()\n",
    "\n",
    "log_mel_spec_mary = get_melspec(resynthesized_mary.type(torch.FloatTensor))\n",
    "\n",
    "ground_truth_matrix =ground_truth.permute((0,2,1)) #(16,1,4)\n",
    "\n",
    "for i in range(500):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    feats = model.extract_features(torch.unsqueeze(log_mel_spec_mary,dim=0))[0] #(4,1,16)\n",
    "    feats=feats.permute((2,1,0)) #(16,1,4)\n",
    "    output = torch.nn.functional.sigmoid(feats*10).type(torch.DoubleTensor)\n",
    "\n",
    "    synthesized_audio = FunctionWithNumericalGrad.apply(output)\n",
    "    \n",
    "    #synthesized_audio = sampler(output,samples)\n",
    "    log_mel_spec_concat = get_melspec(synthesized_audio)\n",
    "\n",
    "    loss_val = loss(log_mel_spec_concat,log_mel_spec_mary)\n",
    "    loss_val.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"Loss is: \", loss_val)\n",
    "\n",
    "if not os.path.isdir(\"reconstruction\"):\n",
    "    os.mkdir(\"reconstruction\")\n",
    "\n",
    "sf.write(\"reconstruction/resynthesized_mary.wav\", resynthesized_mary.permute(1,0).detach().numpy(), 44100)\n",
    "sf.write(\"reconstruction/synthesized_audio.wav\", synthesized_audio.permute(1,0).detach().numpy(), 44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31843bc3e5bd3cc547d89de996a9ff9632c278e18ec25bf07db49190e7c31155"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('msynthconda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
